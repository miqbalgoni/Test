{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page 129 of Python for Algorithmic Trading from idea to cloud deployment \n",
    "# Machine Learning\n",
    "# Linear Regression\n",
    "# Predicting price od EURUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import random \n",
    "import numpy as np \n",
    "from pylab import mpl, plt \n",
    "\n",
    "plt.style.use('seaborn') \n",
    "mpl.rcParams['savefig.dpi'] = 300 \n",
    "mpl.rcParams['font.family'] = 'serif' \n",
    "os.environ['PYTHONHASHSEED'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('http://hilpisch.com/pyalgo_eikon_eod_data.csv', index_col=0, parse_dates=True).dropna()\n",
    "#raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Procedure as in the example before this but lag taken as 5 instead of 3\n",
    "#  We are trying to predict PRICE LEVEL itself for the next day based on Today's price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'EUR='\n",
    "data = pd.DataFrame(raw[symbol])  # extract EURUSD from the df\n",
    "data.rename(columns={symbol: 'price'}, inplace=True)\n",
    "train_data=pd.DataFrame()\n",
    "train_data['price'] = data['price'].loc[:'2019-10-31']\n",
    "#print(data.loc['2019-11-04'])\n",
    "test_data=pd.DataFrame()\n",
    "test_data['price'] = data['price'].loc['2019-11-1':]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_Test(lags, data1):\n",
    "    #lags=5\n",
    "    data=pd.DataFrame(index=data1.index)\n",
    "    data['price']=data1['price']\n",
    "    cols = []\n",
    "    #print(data)\n",
    "    for lag in range(1, lags + 1):                                           #This loop will delete first 5 rows on every call of function\n",
    "        col = f'lag_{lag}' \n",
    "        data[col] = data['price'].shift(lag) \n",
    "        cols.append(col) \n",
    "    #print(data)    \n",
    "    data.dropna(inplace=True)  #-------------------------\n",
    "    #print(data)\n",
    "    #print(data[cols])\n",
    "    reg = np.linalg.lstsq(data[cols], data['price'], rcond=None)[0]\n",
    "    #print(reg)\n",
    "    data['prediction'] = np.dot(data[cols], reg)\n",
    "    #data[['price', 'prediction']].plot(figsize=(10, 6));\n",
    "    #data[['price', 'prediction']].loc['2019-10-1':].plot( figsize=(10, 6));\n",
    "    #print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg = np.linalg.lstsq(data[cols], data['price'], rcond=None)[0]  #Here, data[cols] is the independent variables & price is dependent variable \n",
    "#reg # As we can see from results of regression, 98.64% is explained by the yesterday's price only and that's COOOOOOLLLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['prediction'] = np.dot(data[cols], reg)\n",
    "#data[['price', 'prediction']].plot(figsize=(10, 6));\n",
    "#data[['price', 'prediction']].loc['2019-12-1':].plot( figsize=(10, 6)); # We decrease the time to get an idea\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1148, 1.11086, 1.115, -1, 1], [1.115, 1.11461, 1.1165, -1, 1], [1.1165, 1.11489, 1.1126, -1, -1], [1.1126, 1.11634, 1.1074, 1, -1], [1.1074, 1.11255, 1.1065, 1, -1], [1.1065, 1.10733, 1.1049, 1, -1], [1.1049, 1.10634, 1.1016, 1, -1], [1.1016, 1.10481, 1.1032, 1, 1], [1.1032, 1.10153, 1.1007, -1, -1], [1.1007, 1.10301, 1.1006, 1, -1], [1.1006, 1.10065, 1.1021, 1, 1], [1.1021, 1.10047, 1.105, -1, 1], [1.105, 1.10197, 1.107, -1, 1], [1.107, 1.10486, 1.1078, -1, 1], [1.1078, 1.10689, 1.1072, -1, -1], [1.1072, 1.10769, 1.1057, 1, -1], [1.1057, 1.1071, 1.1022, 1, -1], [1.1022, 1.1056, 1.1013, 1, -1], [1.1013, 1.10214, 1.1018, 1, 1], [1.1018, 1.10116, 1.0998, -1, -1], [1.0998, 1.10167, 1.1015, 1, 1], [1.1015, 1.09974, 1.1077, -1, 1], [1.1077, 1.10133, 1.1081, -1, 1], [1.1081, 1.10751, 1.1076, -1, -1], [1.1076, 1.10809, 1.1102, 1, 1], [1.1102, 1.10751, 1.1057, -1, -1], [1.1057, 1.11005, 1.1062, 1, 1], [1.1062, 1.10575, 1.1092, -1, 1], [1.1092, 1.10604, 1.1128, -1, 1], [1.1128, 1.10907, 1.1128, -1, 1], [1.1128, 1.1127, 1.1119, -1, -1], [1.1119, 1.11278, 1.1142, 1, 1], [1.1142, 1.11186, 1.1149, -1, 1], [1.1149, 1.11411, 1.1111, -1, -1], [1.1111, 1.11485, 1.112, 1, 1], [1.112, 1.11112, 1.1078, -1, -1], [1.1078, 1.1119, 1.1086, 1, 1], [1.1086, 1.10781, 1.1087, -1, 1], [1.1087, 1.1085, 1.1096, -1, 1], [1.1096, 1.10864, 1.1175, -1, 1], [1.1175, 1.10953, 1.1197, -1, 1]]\n"
     ]
    }
   ],
   "source": [
    "#print(train_data)\n",
    "work_data=pd.DataFrame()#data=None, columns=test_data.columns, index=test_data.index)\n",
    "work_data = train_data.copy()\n",
    "\n",
    "#Compare and store the prediction with the unseen data & than add the same to train_data\n",
    "# Means add one row and retrain the data to get new prediction for next day & continue the process till\n",
    "#  test data is exhausted \n",
    "\n",
    "res_elva_test = []\n",
    "for i in range(0,test_data.shape[0]) :\n",
    "    wo_data=pd.DataFrame()#data=None, columns=test_data.columns)#, index=test_data.index)\n",
    "    work_data = LR_Test(3,work_data)                             # I am using 1 lag instead of 5 lags -----------------------------\n",
    "    #print(work_data)\n",
    "    #print(work_data['price'][-2])\n",
    "    #print(work_data['prediction'][-2])\n",
    "    #print(work_data['price'][-1])\n",
    "    Test_List = [round(work_data['price'][-2],5), round(work_data['prediction'][-2],5), round(work_data['price'][-1],5)]\n",
    "    Pred_Direc = -1 if ((Test_List[1] - Test_List[0]) < 0 ) else 1\n",
    "    Test_List.append(Pred_Direc)\n",
    "    Actual_Direc = -1 if ((Test_List[2] - Test_List[0]) < 0 ) else 1\n",
    "    Test_List.append(Actual_Direc)\n",
    "    res_elva_test.append(Test_List)\n",
    "    #print(Test_List)\n",
    "    entries=[]\n",
    "    entries.append((test_data.iloc[[i]]))\n",
    "    wo_data = pd.concat(entries)\n",
    "   \n",
    "    work_data = pd.concat([work_data, wo_data])\n",
    "\n",
    "\n",
    "print(res_elva_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 23\n",
      "Accuracy = 43.9 Percent\n"
     ]
    }
   ],
   "source": [
    "P=0\n",
    "N=0\n",
    "for i in range(0,len(res_elva_test)):\n",
    "    if res_elva_test[i][3]==res_elva_test[i][4]:\n",
    "        P+=1\n",
    "        \n",
    "    else:\n",
    "        N+=1\n",
    "print(P, N)\n",
    "print(f\"Accuracy = %s Percent\"% round((P/(P+N))*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
